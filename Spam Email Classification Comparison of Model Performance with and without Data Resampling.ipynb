{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMhHtZUmECnnFmP1bmhMaf9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Utkarshmishra2k2/Spam-Email-Classification-Comparison-of-Model-Performance-with-and-without-Data-Resampling/blob/main/Spam%20Email%20Classification%20Comparison%20of%20Model%20Performance%20with%20and%20without%20Data%20Resampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "Spam email classification is a critical task in the world of machine learning, natural language processing (NLP), and cybersecurity. Spam emails are unsolicited or unwanted messages, often aimed at promoting products, phishing, or spreading malware. The ability to automatically detect and classify these messages as \"spam\" or \"not spam\" can save users time, enhance productivity, and improve the security of their email systems.\n",
        "\n",
        "In this project, we aim to build a spam email classifier using the Naïve Bayes algorithm and compare its performance with and without data resampling techniques like Synthetic Minority Over-sampling Technique (SMOTE). The Naïve Bayes algorithm is widely used for text classification tasks due to its simplicity and effectiveness, especially when the features are conditionally independent, which is a common assumption for text data. We will also explore the impact of data resampling on classifier performance, given that spam datasets are often imbalanced, with far fewer spam emails compared to legitimate ones."
      ],
      "metadata": {
        "id": "Qd2v-DFhgGJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why Use Naïve Bayes Algorithm?\n",
        "The Naïve Bayes (NB) algorithm is particularly suited for text classification tasks, like spam email detection, for the following reasons:\n",
        "\n",
        "1. Simplicity: Naïve Bayes is simple and computationally efficient, making it easy to implement and fast to train.\n",
        "2. Effectiveness with Text Data: It works well for high-dimensional data, such as text, by treating each word or feature as independent (the \"naïve\" assumption).\n",
        "3. Probabilistic Output: Naïve Bayes provides the probability of a given email being spam or not, making it useful in decision-making.\n",
        "4. Works Well with Imbalanced Data: While Naïve Bayes assumes feature independence, it often performs well on imbalanced datasets where one class (e.g., non-spam) dominates.\n",
        "\n",
        "\n",
        "In this project, we will apply the Multinomial Naïve Bayes classifier to predict whether emails are spam or not and compare its performance with and without data resampling."
      ],
      "metadata": {
        "id": "2N-ujWjxgLxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aim of the Project\n",
        "The primary goal of this project is to:\n",
        "\n",
        "* Train a spam email classifier using the Naïve Bayes algorithm.\n",
        "* Evaluate the performance of the model on a real-world email dataset, using metrics like accuracy, precision, recall, and F1-score.\n",
        "* Compare the model's performance with and without applying data resampling techniques (such as SMOTE) to address class imbalance."
      ],
      "metadata": {
        "id": "NxgYnuLxgamE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries\n"
      ],
      "metadata": {
        "id": "GXvK7pi-U5vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, roc_curve, auc, precision_recall_curve, classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "Q-vUeRDfyANw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ],
      "metadata": {
        "id": "czJRB8HdMlx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "PSxnk6bSyO9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Basic Exploration"
      ],
      "metadata": {
        "id": "VkdSUyBJVAlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"jackksoncsie/spam-email-dataset\")"
      ],
      "metadata": {
        "id": "ow_IsDnj8WMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_01 = pd.read_csv(path + \"/emails.csv\")"
      ],
      "metadata": {
        "id": "HWd596rwyPaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_01.sample(5)"
      ],
      "metadata": {
        "id": "RLrCxIEIysAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_01.shape"
      ],
      "metadata": {
        "id": "ujo3dO0YzCDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_01.isnull().sum()"
      ],
      "metadata": {
        "id": "WytyrlCAzGPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_01.info()"
      ],
      "metadata": {
        "id": "gTFmC34S5U_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_01.describe()"
      ],
      "metadata": {
        "id": "qfpFjjyRzLa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization"
      ],
      "metadata": {
        "id": "8L2RAuXLVYXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  1. Spam Distribution"
      ],
      "metadata": {
        "id": "46uuragmVFKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spam_counts = data_01['spam'].map({1:\"Spam\",0:\"Not Spam\"}).value_counts()\n",
        "\n",
        "fig = px.pie(\n",
        "    names=spam_counts.index,\n",
        "    values=spam_counts.values,\n",
        "    title='Distribution of Spam vs Not Spam Emails',\n",
        "    color=spam_counts.index,\n",
        "    color_discrete_map={'Spam': 'lightblue', 'Not Spam': 'pink'},\n",
        "    labels={'spam_or_not': 'Spam or Not'},\n",
        "    template='plotly_dark',\n",
        "    hole=0.3\n",
        "\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Duiieqt-zxSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "1. Proportion of Spam Emails:\n",
        "The proportion of spam emails is 23.9%. This suggests that approximately one-quarter of the emails analyzed were classified as spam.\n",
        "2. Proportion of Non-Spam Emails:\n",
        "The proportion of non-spam emails is 76.1%. This indicates that the majority of emails (approximately three-quarters) were not categorized as spam.\n",
        "3. Overall Spam Rate:\n",
        "The overall spam rate is 23.9%. This means that out of every 100 emails, on average, 24 are likely to be spam."
      ],
      "metadata": {
        "id": "kQfQqDkZhhLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Text Length Distribution by Spam Classification\n"
      ],
      "metadata": {
        "id": "GqGcd9maVI-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_02 = data_01.copy()"
      ],
      "metadata": {
        "id": "3i3bRzmU6-4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_02['spam_label'] = data_02['spam'].map({0: 'Not Spam', 1: 'Spam'})\n",
        "data_02['text_length'] = data_02['text'].apply(len)\n",
        "fig = px.histogram(data_02, x='text_length', color='spam_label', nbins=50, template='plotly_dark', title='Text Length Distribution by Spam/Not Spam')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "jSgET6Om1UjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "\n",
        "The histogram shows a clear difference in the distribution of text lengths between spam and non-spam messages.\n",
        "\n",
        "Spam messages tend to have shorter text lengths, with a majority falling within the 0-10k range.\n",
        "Non-spam messages exhibit a wider range of text lengths, with a significant portion extending beyond 10k characters.\n",
        "\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "This pattern suggests that text length could be a potential feature for distinguishing spam from non-spam messages. Spammers may often use concise, repetitive messages to maximize their reach, while legitimate messages often contain more detailed content."
      ],
      "metadata": {
        "id": "ix9Loe4IiIe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.box(\n",
        "    data_02,\n",
        "    x='spam_label',\n",
        "    y='text_length',\n",
        "    color='spam_label',\n",
        "    title='Distribution of Text Length in Emails by Spam Classification',\n",
        "    color_discrete_map={'spam': 'red', 'not_spam': 'green'},  # Custom color map for spam vs. not_spam\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Distribution of Text Length in Emails by Spam Classification',\n",
        "    xaxis_title='Email Classification (Spam or Not Spam)',\n",
        "    yaxis_title='Text Length (in characters)',\n",
        "    boxmode='group',\n",
        "    showlegend=False,\n",
        "    plot_bgcolor='rgba(0, 0, 0, 0)',\n",
        "    template='plotly_dark',\n",
        "    xaxis=dict(\n",
        "        tickmode='array',\n",
        "        tickvals=['spam', 'not_spam'],\n",
        "        ticktext=['Spam Emails', 'Non-Spam Emails']\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        zeroline=True,\n",
        "        showgrid=True,\n",
        "        )\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Y9NxQOJQ2u6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "\n",
        "The boxplot shows that spam emails are mostly short, with a median around 500 characters and a few long outliers. Non-spam emails have a wider range and a median of 2,000 characters.\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "This suggests that text length could help distinguish spam from non-spam, as spam tends to be concise, while non-spam is more detailed.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Nyn-haYoikl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Word Clouds for Spam and Non-Spam Emails"
      ],
      "metadata": {
        "id": "H-TQzPgxVR_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_01['text'] = data_01['text'].astype(str)"
      ],
      "metadata": {
        "id": "zQiDAQvK6mEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam_text = \" \".join(str(email) for email in data_01[data_01['spam'] == 1]['text'])\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "spam_wordcloud = WordCloud(\n",
        "    width=800,\n",
        "    height=400,\n",
        "    background_color='black',\n",
        "    colormap='plasma',\n",
        "    max_words=200,\n",
        "    stopwords=stop_words,\n",
        "    contour_color='white',\n",
        "    contour_width=2,\n",
        "    random_state=42\n",
        ").generate(spam_text)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(spam_wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Top Words in Spam Emails', fontsize=16, color='white', fontweight='bold')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kyVBX60D3m8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "\n",
        "The word cloud provides a visual representation of the most frequent words in a dataset, likely related to email content. The size of each word is proportional to its frequency in the text.\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "* Common Themes: The dominant words like \"email,\" \"website,\" \"company,\" \"business,\n",
        "\" \"money,\" \"information,\" and \"product\" suggest that the dataset is likely composed of emails related to business transactions, marketing, or online activities.\n",
        "* Action-Oriented: Words like \"click,\" \"order,\" \"get,\" \"find,\" \"make,\" and \"need\" indicate a focus on action-oriented communication and requests.\n",
        "* Marketing and Sales: Terms like \"offer,\" \"free,\" \"save,\" and \"investment\" suggest a marketing or sales context, potentially for online products or services."
      ],
      "metadata": {
        "id": "nLErETRoiyCU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. Word Clouds for Non-Spam Emails"
      ],
      "metadata": {
        "id": "gOXR_y-aVoud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spam_text = \" \".join(str(email) for email in data_01[data_01['spam'] == 0]['text'])\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "spam_wordcloud = WordCloud(\n",
        "    width=800,\n",
        "    height=400,\n",
        "    background_color='black',\n",
        "    colormap='plasma',\n",
        "    max_words=200,\n",
        "    stopwords=stop_words,\n",
        "    contour_color='white',\n",
        "    contour_width=2,\n",
        "    random_state=42\n",
        ").generate(spam_text)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(spam_wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Top Words in Not Spam Emails', fontsize=16, color='white', fontweight='bold')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EbHYFvFE5P0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "\n",
        "The word cloud provides a visual representation of the most frequent words in a dataset, likely related to email content. The size of each word is proportional to its frequency in the text.\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "* Common Themes: The dominant words like \"enron,\" \"kaminski,\" \"vince,\" \"subject,\" \"email,\" \"meeting,\" \"project,\" \"would,\" and \"like\" suggest that the dataset is likely composed of internal company emails, potentially related to project management or team communication.\n",
        "* Action-Oriented: Words like \"plan,\" \"discuss,\" \"update,\" \"need,\" and \"get\" indicate a focus on action-oriented communication and requests.\n",
        "* Company-Specific: The presence of names like \"Kaminski\" and \"Vince\" suggests that the emails might be specific to certain individuals or teams within the company."
      ],
      "metadata": {
        "id": "Y7Bb61V9jH_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_common_words(data, label, title):\n",
        "    filtered_data = data[data['spam'] == label]\n",
        "\n",
        "    if filtered_data.empty:\n",
        "        print(f\"No data available for label {label}.\")\n",
        "        return\n",
        "\n",
        "    vectorizer = CountVectorizer(stop_words='english', max_features=30)\n",
        "    words_data = vectorizer.fit_transform(filtered_data['text'])\n",
        "\n",
        "    words = vectorizer.get_feature_names_out()\n",
        "    counts = words_data.sum(axis=0).A1\n",
        "\n",
        "    word_counts = pd.DataFrame({'word': words, 'count': counts}).sort_values(by='count', ascending=False)\n",
        "\n",
        "    fig = px.bar(\n",
        "        word_counts,\n",
        "        x='word',\n",
        "        y='count',\n",
        "        title=title,\n",
        "        labels={'word': 'Word', 'count': 'Frequency'},\n",
        "        color='count',\n",
        "        color_continuous_scale='Viridis',\n",
        "        text='count'\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        xaxis_title='Words',\n",
        "        yaxis_title='Frequency',\n",
        "        xaxis_tickangle=-45,\n",
        "        plot_bgcolor='rgba(0, 0, 0, 0)',\n",
        "        template='plotly_dark',\n",
        "        showlegend=False\n",
        "    )\n",
        "\n",
        "    fig.show()\n"
      ],
      "metadata": {
        "id": "WDbhWpcQ7hs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1. Common Words in Spam Emails\n"
      ],
      "metadata": {
        "id": "_t3lVHy7V3bs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_common_words(data_01, 1, 'Top 30 Most Common Words in Spam Emails')"
      ],
      "metadata": {
        "id": "C86LAmYs8JuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "The bar chart displays the frequency of the top 30 most common words found in spam emails.\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "* High-Frequency Words: Words like \"subject,\" \"address,\" \"information,\" and \"money\" appear frequently in spam emails. These words might be used by spammers to attract attention or to disguise their malicious intent.\n",
        "* Action-Oriented Words: Words like \"click,\" \"free,\" and \"order\" are also common, suggesting that spam emails often try to entice recipients to take specific actions, such as clicking on links or providing personal information.\n",
        "* Technical Terms: Words like \"software\" and \"website\" might be used to create a sense of legitimacy or to mask the true nature of the spam email."
      ],
      "metadata": {
        "id": "GooRw2KKjhEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2. Common Words in Non-Spam Emails\n"
      ],
      "metadata": {
        "id": "7rFLZUA6V9rO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_common_words(data_01, 0, 'Top 30 Most Common Words in Non-Spam Emails')"
      ],
      "metadata": {
        "id": "agO6bTX0EgLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "\n",
        "The bar chart displays the frequency of the top 30 most common words found in non-spam emails.\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "* Common Business Terms: Words like \"enron,\" \"kaminski,\" \"vince,\" \"subject,\" and \"meeting\" are highly frequent, suggesting a business context.\n",
        "* Action-Oriented Words: Terms like \"know,\" \"thanks,\" \"time,\" and \"energy\" indicate a focus on communication, planning, and problem-solving.\n",
        "* Company-Specific Jargon: The presence of names like \"Kaminski\" and \"Vince\" suggests that the emails might be specific to certain individuals or teams within the company."
      ],
      "metadata": {
        "id": "rr1oSJMyjxk8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Preprocessing: Cleaning and Tokenization"
      ],
      "metadata": {
        "id": "cbAqZAJPWQbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('[^a-zA-Z\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "ImB92FsWFUUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_sentences = [clean_text(text) for text in data_01['text']]"
      ],
      "metadata": {
        "id": "5sn16nrGH92f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction: TF-IDF Vectorization"
      ],
      "metadata": {
        "id": "tM61wqCnWaYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(max_features=2500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))"
      ],
      "metadata": {
        "id": "SqMNwVg3NeXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = vectorizer.fit_transform(X_sentences).toarray()\n",
        "Y = data_01[\"spam\"]"
      ],
      "metadata": {
        "id": "8kqPF58ONKGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train-Test Split"
      ],
      "metadata": {
        "id": "LvSLbft1WfPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "YdW1PvDKI9NG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train Class Distribution:\\n{Y_train.value_counts()}\")"
      ],
      "metadata": {
        "id": "-0MvXpJIQiqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6T5Qk7fJW2tH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Without Data Resampling**\n"
      ],
      "metadata": {
        "id": "-QFjp82jQYbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training: Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "A7Ni1GdoW7oW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_01 = MultinomialNB()"
      ],
      "metadata": {
        "id": "p63YXdgbJKD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_01.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "VGVFV0-PJLha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred_01 = model_01.predict(X_test)"
      ],
      "metadata": {
        "id": "3vZ6I3URJVLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "_ta5bXL0XC--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test Accuracy: {accuracy_score(Y_test, Y_pred_01):}\")"
      ],
      "metadata": {
        "id": "Rmmjm_VBJZ7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test accuracy is 97.81%, meaning the model correctly classified 97.81% of the test samples. This shows that the model performs well on new, unseen data, accurately predicting whether an email is spam or not in nearly 98 out of 100 cases."
      ],
      "metadata": {
        "id": "y8MfPZvxkir1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(Y_test, Y_pred_01, target_names=['Not Spam', 'Spam']))"
      ],
      "metadata": {
        "id": "py6w7tIvS0RV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(Y_test, Y_pred_01)\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Not Spam\", \"Spam\"], yticklabels=[\"Not Spam\", \"Spam\"])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bo7yCCnYNwte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation:\n",
        "\n",
        "* True Positives (TP): 849 emails were correctly classified as non-spam.\n",
        "* True Negatives (TN): 272 emails were correctly classified as spam.\n",
        "* False Positives (FP): 7 non-spam emails were incorrectly classified as spam.\n",
        "* False Negatives (FN): 18 spam emails were incorrectly classified as non-spam.\n"
      ],
      "metadata": {
        "id": "bQYhy2CakQVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **ROC Curve**"
      ],
      "metadata": {
        "id": "5Dkq8-MwXMZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob = model_01.predict_proba(X_test)[:,1]\n",
        "fpr, tpr, _ = roc_curve(Y_test, Y_pred_01)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "fig = px.area(\n",
        "    x=fpr, y=tpr,\n",
        "    title=f'ROC Curve (AUC = {roc_auc:.2f})',\n",
        "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
        "    width=600, height=400\n",
        ")\n",
        "fig.add_shape(\n",
        "    type='line', line=dict(dash='dash'),\n",
        "    x0=0, x1=1, y0=0, y1=1\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "E4Qf61esJbvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation:**\n",
        "\n",
        "* AUC Score (0.96): An AUC score of 0.96 indicates that the model has excellent discriminatory power. It is significantly better than a random classifier (which would have an AUC of 0.5).\n",
        "* ROC Curve Shape: The ROC curve shows that as the false positive rate (FPR) increases, the true positive rate (TPR) also increases, indicating that the model is effectively distinguishing between positive and negative classes.\n",
        "* Trade-off: The ROC curve highlights the trade-off between sensitivity (TPR) and specificity (1-FPR). Different points on the curve represent different threshold settings, and the optimal threshold can be chosen based on the specific needs of the application."
      ],
      "metadata": {
        "id": "fXU68UeLlRGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Precision-Recall Curve**"
      ],
      "metadata": {
        "id": "CL5Rc28qXRA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision-Recall Curve\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(Y_test, Y_pred_01)\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=recall, y=precision, mode='lines', name='Precision-Recall Curve'))\n",
        "fig.update_layout(title=\"Precision-Recall Curve\", xaxis_title=\"Recall\", yaxis_title=\"Precision\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ex4WOBNZJ94m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation:**\n",
        "* High Precision, High Recall: The curve shows that the model achieves high precision and recall across a wide range of thresholds. This indicates that the model is effective in both identifying true positive cases and avoiding false positives.\n",
        "* Steep Drop: The sharp drop in precision at higher recall values suggests that the model might have difficulty correctly classifying some of the positive cases, leading to a decrease in precision.\n",
        "* Trade-off: The curve highlights the trade-off between precision and recall. As the threshold for classifying a case as positive is lowered to increase recall, precision might decrease, and vice versa."
      ],
      "metadata": {
        "id": "mTO-92anliEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Cross-Validation"
      ],
      "metadata": {
        "id": "C1zZoBe8Xf94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation\n",
        "cross_val_scores = cross_val_score(model_01, X, Y, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-Validation Accuracy Scores: {cross_val_scores}\")\n",
        "print(f\"Mean Cross-Validation Accuracy: {cross_val_scores.mean():}\")"
      ],
      "metadata": {
        "id": "EWmEulkbN2ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These results show that the model consistently performs well across different folds, with a mean accuracy of approximately 98.15%, indicating stable and reliable performance."
      ],
      "metadata": {
        "id": "N56YjsshlsV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "ry1DcjaAXkD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tuning with GridSearchCV\n",
        "param_grid = {'alpha': [0.1, 0.5, 1.0, 2.0, 3.0]}\n",
        "grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "MM5qtCB3N5QU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation score: {grid_search.best_score_:.2f}\")"
      ],
      "metadata": {
        "id": "u869y3agN7Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model's optimal performance was achieved with an alpha value of 0.1, resulting in a high cross-validation score of 98%, indicating that this setting provides the best generalization across the folds."
      ],
      "metadata": {
        "id": "PAE46r_-lyBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid_search.best_estimator_\n",
        "Y_pred_best = best_model.predict(X_test)"
      ],
      "metadata": {
        "id": "Z_InPW4EN-K1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test Accuracy: {accuracy_score(Y_test, Y_pred_best):}\")"
      ],
      "metadata": {
        "id": "r1Rx9mEuXvQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(Y_test, Y_pred_best, target_names=['Not Spam', 'Spam']))"
      ],
      "metadata": {
        "id": "i_nupTxkXvQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(Y_test, Y_pred_best)\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Not Spam\", \"Spam\"], yticklabels=[\"Not Spam\", \"Spam\"])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P9ts8pZdXvQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **With Data Resampling {SMOTE}**\n"
      ],
      "metadata": {
        "id": "sBnh7pYOQaVY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Imbalanced Data using SMOTE (Synthetic Minority Over-sampling Technique)\n"
      ],
      "metadata": {
        "id": "ie0XnGUKYR6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Before SMOTE - Train class distribution:\\n{Y_train.value_counts()}\")"
      ],
      "metadata": {
        "id": "BwA0M3ooSf-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, Y_train_resampled = smote.fit_resample(X_train, Y_train)"
      ],
      "metadata": {
        "id": "p6abxkHqLfR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"After SMOTE - Resampled train class distribution:\\n{Y_train_resampled.value_counts()}\")"
      ],
      "metadata": {
        "id": "ZU-vopDGRyPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training: Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "TBAE3xLqYdbW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "t45JfKzLYdbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_02 = MultinomialNB()"
      ],
      "metadata": {
        "id": "wyWoekyFR77E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_02.fit(X_train_resampled, Y_train_resampled)"
      ],
      "metadata": {
        "id": "6ZICfRAgR77F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_02 = model_02.predict(X_test)"
      ],
      "metadata": {
        "id": "sZo8rVLWR77F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test Accuracy: {accuracy_score(Y_test, y_pred_02):}\")"
      ],
      "metadata": {
        "id": "ml6Yu_5Tbz5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test accuracy is 98.86%, meaning the model correctly classified 98.86% of the test samples. This shows that the model performs well on new, unseen data, accurately predicting whether an email is spam or not in nearly 99 out of 100 cases."
      ],
      "metadata": {
        "id": "nEJ-UppMmBV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(Y_test, y_pred_02, target_names=['Not Spam', 'Spam']))"
      ],
      "metadata": {
        "id": "hAhRddsIR77F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(Y_test, y_pred_02)\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Not Spam\", \"Spam\"], yticklabels=[\"Not Spam\", \"Spam\"])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y7IfdYrBR77G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation:\n",
        "\n",
        "* True Positives (TP): 848 emails were correctly classified as non-spam.\n",
        "* True Negatives (TN): 285 emails were correctly classified as spam.\n",
        "* False Positives (FP): 8 non-spam emails were incorrectly classified as spam.\n",
        "* False Negatives (FN): 5 spam emails were incorrectly classified as non-spam.\n"
      ],
      "metadata": {
        "id": "hNT_w829mSg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **ROC Curve**"
      ],
      "metadata": {
        "id": "NSHpcBjLYdbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROC Curve\n",
        "\n",
        "y_prob = model_02.predict_proba(X_test)[:,1]\n",
        "fpr, tpr, _ = roc_curve(Y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "fig = px.area(\n",
        "    x=fpr, y=tpr,\n",
        "    title=f'ROC Curve (AUC = {roc_auc:.2f})',\n",
        "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
        "    width=600, height=400\n",
        ")\n",
        "fig.add_shape(\n",
        "    type='line', line=dict(dash='dash'),\n",
        "    x0=0, x1=1, y0=0, y1=1\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ya3-XSEgR77F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Precision-Recall Curve**"
      ],
      "metadata": {
        "id": "EaDS2ZX4YdbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision-Recall Curve\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(Y_test, y_prob)\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=recall, y=precision, mode='lines', name='Precision-Recall Curve'))\n",
        "fig.update_layout(title=\"Precision-Recall Curve\", xaxis_title=\"Recall\", yaxis_title=\"Precision\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "dxP_ALSsR77G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Cross-Validation"
      ],
      "metadata": {
        "id": "yWuzKngxY-sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation\n",
        "cross_val_scores = cross_val_score(model_02, X, Y, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-Validation Accuracy Scores: {cross_val_scores}\")\n",
        "print(f\"Mean Cross-Validation Accuracy: {cross_val_scores.mean():}\")"
      ],
      "metadata": {
        "id": "eLBJ2-juR77G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These results show that the model consistently performs well across different folds, with a mean accuracy of approximately 98.15%, indicating stable and reliable performance."
      ],
      "metadata": {
        "id": "JlTTPmOgmgvR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "w8zt_JFMZMYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tuning with GridSearchCV\n",
        "param_grid = {'alpha': [0.1, 0.5, 1.0, 2.0, 3.0]}\n",
        "grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "Umoob5EoR77G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation score: {grid_search.best_score_:.2f}\")"
      ],
      "metadata": {
        "id": "ejGr-kjBR77G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid_search.best_estimator_\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "print(f\"Test Accuracy with best model: {accuracy_score(Y_test, y_pred_best):}\")"
      ],
      "metadata": {
        "id": "XhxmIi_LR77G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Benchmarking"
      ],
      "metadata": {
        "id": "B3lh1hoKmt_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_emails = X_test[:10]\n",
        "sample_labels = Y_test[:10]\n",
        "sample_predictions = model_02.predict(sample_emails)"
      ],
      "metadata": {
        "id": "47yKpKK4R77G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_predictions"
      ],
      "metadata": {
        "id": "iuYhdCbpmxkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (X_sentences[56])\n",
        "print (Y[56])"
      ],
      "metadata": {
        "id": "c7AB8P6RR77G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (model_02.predict(vectorizer.transform([X_sentences[56]])))"
      ],
      "metadata": {
        "id": "a1XPRjLwR77H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion:\n",
        "The project successfully demonstrated the importance of handling imbalanced datasets when building classification models. Without data resampling, the model struggled to correctly classify spam emails due to the imbalance in the dataset. However, after applying SMOTE, the model's ability to classify both spam and non-spam emails improved significantly. This shows that SMOTE is an effective technique for improving the performance of machine learning models when working with imbalanced data.\n",
        "\n",
        "Further improvements could involve exploring other resampling techniques, such as undersampling the majority class or using more complex models like Random Forests or Gradient Boosting Machines. Additionally, fine-tuning the model with more advanced text representation techniques (e.g., Word2Vec or transformers) could further enhance the classification accuracy.\n",
        "\n",
        "Ultimately, this project demonstrates the power of preprocessing and resampling techniques in building robust spam email classifiers, which could be applied in real-world email filtering systems to reduce unwanted spam emails efficiently."
      ],
      "metadata": {
        "id": "VaT4rvc1nXXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"End\")"
      ],
      "metadata": {
        "id": "_FCbfKBhT2E7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}